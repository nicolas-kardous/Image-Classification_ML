{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"GradProject_NB4.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uMm6H38-PVDL","colab_type":"text"},"source":["<h1> DS200A Computer Vision Assignment</h1>"]},{"cell_type":"markdown","metadata":{"id":"A9Ok6LuuPVDU","colab_type":"text"},"source":["<h2>  Part Four: Neural networks </h2>\t\n"]},{"cell_type":"markdown","metadata":{"id":"tH1ic-81LZle","colab_type":"text"},"source":["https://towardsdatascience.com/training-a-convolutional-neural-network-from-scratch-2235c2a25754\n","https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\n","https://visualstudiomagazine.com/articles/2018/12/01/image-classification-keras.aspx\n","https://medium.com/nybles/create-your-first-image-recognition-classifier-using-cnn-keras-and-tensorflow-backend-6eaab98d14dd\n","https://towardsdatascience.com/image-recognition-with-keras-convolutional-neural-networks-e2af10a10114\n","https://github.com/keras-team/keras/issues/3109\n"]},{"cell_type":"code","metadata":{"id":"A7G81XnYITdN","colab_type":"code","colab":{}},"source":["import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.utils import to_categorical\n","from keras.preprocessing import image\n","from tqdm import tqdm\n","\n","import seaborn as sns\n","\n","import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import skimage\n","import sklearn\n","from sklearn import preprocessing\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import RFE\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","from sklearn.linear_model import LassoCV\n","from sklearn.tree import DecisionTreeClassifier\n","\n","\n","from sklearn import metrics\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import auc\n","from sklearn.metrics import roc_curve\n","%matplotlib inline\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxmzdSrvKNB2","colab_type":"code","outputId":"4c24fd1f-3ee7-4c98-9c77-feccb1247804","executionInfo":{"status":"ok","timestamp":1576308479238,"user_tz":480,"elapsed":1348,"user":{"displayName":"Emeri Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcxUiKuckdyRohPCkNf6AzIIN4Fo74NBwrQfHk7Q=s64","userId":"09196877081073417019"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BVqRd_w7IVPd","colab_type":"code","outputId":"ac090d5a-e05e-4e23-dc7f-62a5bc1c86c6","executionInfo":{"status":"ok","timestamp":1576308490934,"user_tz":480,"elapsed":10713,"user":{"displayName":"Emeri Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcxUiKuckdyRohPCkNf6AzIIN4Fo74NBwrQfHk7Q=s64","userId":"09196877081073417019"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["#Dataset load and preprocessing SOURCE Rohan BAIR\n","def read_data():\n","  \n","  img_list, label_list = [], []\n","\n","  file_path = os.path.join(os.getcwd(), 'drive/My Drive/D100_Final_Project/20_categories_training')\n","    \n"," \n","  folders = os.listdir(file_path)\n","  folders.sort()\n","\n","  i = 0\n","  for file_name in folders: #for each subfolder\n","      if file_name.startswith('.'): #image name format ._\n","          continue\n","      print(file_name) #checkpoint\n","\n","      for image_file in os.listdir(os.path.join(file_path, file_name)):\n","          if image_file.startswith('.'):\n","              continue\n","          image_file = os.path.join(file_path, file_name, image_file)\n","          image = cv2.imread(image_file)\n","          #resize each image to the shorter median length 300 \n","          image = cv2.resize(image, (300, 300), cv2.INTER_LINEAR)\n","          img_list.append(image)\n","          label_list.append(i)\n","      i += 1\n","  img_list = np.array(img_list, dtype=np.uint8)\n","  label_list= np.array( label_list, dtype=np.int32 )\n","  img_list = img_list.astype('float32')\n","  #Scale down, normalizing the data\n","  img_list = img_list / 255\n","  return img_list, label_list\n","\n","data, label = read_data()\n","print(data.shape, label.shape)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["airplanes\n","bear\n","blimp\n","comet\n","crab\n","dog\n","dolphin\n","giraffe\n","goat\n","gorilla\n","kangaroo\n","killer-whale\n","leopards\n","llama\n","penguin\n","porcupine\n","teddy-bear\n","triceratops\n","unicorn\n","zebra\n","(1501, 300, 300, 3) (1501,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xwnyGbD-Kl2u","colab_type":"code","outputId":"1cb8bc87-b15d-4c69-ca19-8156f1cfa577","executionInfo":{"status":"ok","timestamp":1576308496784,"user_tz":480,"elapsed":5212,"user":{"displayName":"Emeri Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcxUiKuckdyRohPCkNf6AzIIN4Fo74NBwrQfHk7Q=s64","userId":"09196877081073417019"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def read_val_data():\n","  img_list= []\n","  file_path = os.path.join(os.getcwd(), 'drive/My Drive/D100_Final_Project/20_Validation')\n","  files = os.listdir(file_path)\n","  files.sort()\n","   \n","  for image_file in files: #for each subfolder     \n","      print(image_file) #checkpoint\n","      image_file = os.path.join(file_path, image_file)\n","      image = cv2.imread(image_file)\n","      #resize each image to the shorter median length 300 \n","      image = cv2.resize(image, (300,300), cv2.INTER_LINEAR)\n","      img_list.append(image)\n","  img_list = np.array(img_list, dtype=np.uint8)\n","  img_list = img_list.astype('float32')\n","  #Scale down\n","  img_list = img_list / 255\n","  return img_list\n","\n","val_images= read_val_data()\n","print(val_images.shape)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["validation_pic (1).jpg\n","validation_pic (10).jpg\n","validation_pic (100).jpg\n","validation_pic (101).jpg\n","validation_pic (102).jpg\n","validation_pic (103).jpg\n","validation_pic (104).jpg\n","validation_pic (105).jpg\n","validation_pic (106).jpg\n","validation_pic (107).jpg\n","validation_pic (108).jpg\n","validation_pic (109).jpg\n","validation_pic (11).jpg\n","validation_pic (110).jpg\n","validation_pic (111).jpg\n","validation_pic (112).jpg\n","validation_pic (113).jpg\n","validation_pic (114).jpg\n","validation_pic (115).jpg\n","validation_pic (116).jpg\n","validation_pic (117).jpg\n","validation_pic (118).jpg\n","validation_pic (119).jpg\n","validation_pic (12).jpg\n","validation_pic (120).jpg\n","validation_pic (121).jpg\n","validation_pic (122).jpg\n","validation_pic (123).jpg\n","validation_pic (124).jpg\n","validation_pic (125).jpg\n","validation_pic (126).jpg\n","validation_pic (127).jpg\n","validation_pic (128).jpg\n","validation_pic (129).jpg\n","validation_pic (13).jpg\n","validation_pic (130).jpg\n","validation_pic (131).jpg\n","validation_pic (132).jpg\n","validation_pic (133).jpg\n","validation_pic (134).jpg\n","validation_pic (135).jpg\n","validation_pic (136).jpg\n","validation_pic (137).jpg\n","validation_pic (138).jpg\n","validation_pic (139).jpg\n","validation_pic (14).jpg\n","validation_pic (140).jpg\n","validation_pic (141).jpg\n","validation_pic (142).jpg\n","validation_pic (143).jpg\n","validation_pic (144).jpg\n","validation_pic (145).jpg\n","validation_pic (146).jpg\n","validation_pic (147).jpg\n","validation_pic (148).jpg\n","validation_pic (149).jpg\n","validation_pic (15).jpg\n","validation_pic (150).jpg\n","validation_pic (151).jpg\n","validation_pic (152).jpg\n","validation_pic (153).jpg\n","validation_pic (154).jpg\n","validation_pic (155).jpg\n","validation_pic (156).jpg\n","validation_pic (157).jpg\n","validation_pic (158).jpg\n","validation_pic (159).jpg\n","validation_pic (16).jpg\n","validation_pic (160).jpg\n","validation_pic (161).jpg\n","validation_pic (162).jpg\n","validation_pic (163).jpg\n","validation_pic (164).jpg\n","validation_pic (165).jpg\n","validation_pic (166).jpg\n","validation_pic (167).jpg\n","validation_pic (168).jpg\n","validation_pic (169).jpg\n","validation_pic (17).jpg\n","validation_pic (170).jpg\n","validation_pic (171).jpg\n","validation_pic (172).jpg\n","validation_pic (173).jpg\n","validation_pic (174).jpg\n","validation_pic (175).jpg\n","validation_pic (176).jpg\n","validation_pic (177).jpg\n","validation_pic (178).jpg\n","validation_pic (179).jpg\n","validation_pic (18).jpg\n","validation_pic (180).jpg\n","validation_pic (181).jpg\n","validation_pic (182).jpg\n","validation_pic (183).jpg\n","validation_pic (184).jpg\n","validation_pic (185).jpg\n","validation_pic (186).jpg\n","validation_pic (187).jpg\n","validation_pic (188).jpg\n","validation_pic (189).jpg\n","validation_pic (19).jpg\n","validation_pic (190).jpg\n","validation_pic (191).jpg\n","validation_pic (192).jpg\n","validation_pic (193).jpg\n","validation_pic (194).jpg\n","validation_pic (195).jpg\n","validation_pic (196).jpg\n","validation_pic (197).jpg\n","validation_pic (198).jpg\n","validation_pic (199).jpg\n","validation_pic (2).jpg\n","validation_pic (20).jpg\n","validation_pic (200).jpg\n","validation_pic (201).jpg\n","validation_pic (202).jpg\n","validation_pic (203).jpg\n","validation_pic (204).jpg\n","validation_pic (205).jpg\n","validation_pic (206).jpg\n","validation_pic (207).jpg\n","validation_pic (208).jpg\n","validation_pic (209).jpg\n","validation_pic (21).jpg\n","validation_pic (210).jpg\n","validation_pic (211).jpg\n","validation_pic (212).jpg\n","validation_pic (213).jpg\n","validation_pic (214).jpg\n","validation_pic (215).jpg\n","validation_pic (216).jpg\n","validation_pic (217).jpg\n","validation_pic (218).jpg\n","validation_pic (219).jpg\n","validation_pic (22).jpg\n","validation_pic (220).jpg\n","validation_pic (221).jpg\n","validation_pic (222).jpg\n","validation_pic (223).jpg\n","validation_pic (224).jpg\n","validation_pic (225).jpg\n","validation_pic (226).jpg\n","validation_pic (227).jpg\n","validation_pic (228).jpg\n","validation_pic (229).jpg\n","validation_pic (23).jpg\n","validation_pic (230).jpg\n","validation_pic (231).jpg\n","validation_pic (232).jpg\n","validation_pic (233).jpg\n","validation_pic (234).jpg\n","validation_pic (235).jpg\n","validation_pic (236).jpg\n","validation_pic (237).jpg\n","validation_pic (238).jpg\n","validation_pic (239).jpg\n","validation_pic (24).jpg\n","validation_pic (240).jpg\n","validation_pic (241).jpg\n","validation_pic (242).jpg\n","validation_pic (243).jpg\n","validation_pic (244).jpg\n","validation_pic (245).jpg\n","validation_pic (246).jpg\n","validation_pic (247).jpg\n","validation_pic (248).jpg\n","validation_pic (249).jpg\n","validation_pic (25).jpg\n","validation_pic (250).jpg\n","validation_pic (251).jpg\n","validation_pic (252).jpg\n","validation_pic (253).jpg\n","validation_pic (254).jpg\n","validation_pic (255).jpg\n","validation_pic (256).jpg\n","validation_pic (257).jpg\n","validation_pic (258).jpg\n","validation_pic (259).jpg\n","validation_pic (26).jpg\n","validation_pic (260).jpg\n","validation_pic (261).jpg\n","validation_pic (262).jpg\n","validation_pic (263).jpg\n","validation_pic (264).jpg\n","validation_pic (265).jpg\n","validation_pic (266).jpg\n","validation_pic (267).jpg\n","validation_pic (268).jpg\n","validation_pic (269).jpg\n","validation_pic (27).jpg\n","validation_pic (270).jpg\n","validation_pic (271).jpg\n","validation_pic (272).jpg\n","validation_pic (273).jpg\n","validation_pic (274).jpg\n","validation_pic (275).jpg\n","validation_pic (276).jpg\n","validation_pic (277).jpg\n","validation_pic (278).jpg\n","validation_pic (279).jpg\n","validation_pic (28).jpg\n","validation_pic (280).jpg\n","validation_pic (281).jpg\n","validation_pic (282).jpg\n","validation_pic (283).jpg\n","validation_pic (284).jpg\n","validation_pic (285).jpg\n","validation_pic (286).jpg\n","validation_pic (287).jpg\n","validation_pic (288).jpg\n","validation_pic (289).jpg\n","validation_pic (29).jpg\n","validation_pic (290).jpg\n","validation_pic (291).jpg\n","validation_pic (292).jpg\n","validation_pic (293).jpg\n","validation_pic (294).jpg\n","validation_pic (295).jpg\n","validation_pic (296).jpg\n","validation_pic (297).jpg\n","validation_pic (298).jpg\n","validation_pic (299).jpg\n","validation_pic (3).jpg\n","validation_pic (30).jpg\n","validation_pic (300).jpg\n","validation_pic (301).jpg\n","validation_pic (302).jpg\n","validation_pic (303).jpg\n","validation_pic (304).jpg\n","validation_pic (305).jpg\n","validation_pic (306).jpg\n","validation_pic (307).jpg\n","validation_pic (308).jpg\n","validation_pic (309).jpg\n","validation_pic (31).jpg\n","validation_pic (310).jpg\n","validation_pic (311).jpg\n","validation_pic (312).jpg\n","validation_pic (313).jpg\n","validation_pic (314).jpg\n","validation_pic (315).jpg\n","validation_pic (316).jpg\n","validation_pic (317).jpg\n","validation_pic (318).jpg\n","validation_pic (319).jpg\n","validation_pic (32).jpg\n","validation_pic (320).jpg\n","validation_pic (321).jpg\n","validation_pic (322).jpg\n","validation_pic (323).jpg\n","validation_pic (324).jpg\n","validation_pic (325).jpg\n","validation_pic (326).jpg\n","validation_pic (327).jpg\n","validation_pic (328).jpg\n","validation_pic (329).jpg\n","validation_pic (33).jpg\n","validation_pic (330).jpg\n","validation_pic (331).jpg\n","validation_pic (332).jpg\n","validation_pic (333).jpg\n","validation_pic (334).jpg\n","validation_pic (335).jpg\n","validation_pic (336).jpg\n","validation_pic (337).jpg\n","validation_pic (338).jpg\n","validation_pic (339).jpg\n","validation_pic (34).jpg\n","validation_pic (340).jpg\n","validation_pic (341).jpg\n","validation_pic (342).jpg\n","validation_pic (343).jpg\n","validation_pic (344).jpg\n","validation_pic (345).jpg\n","validation_pic (346).jpg\n","validation_pic (347).jpg\n","validation_pic (348).jpg\n","validation_pic (349).jpg\n","validation_pic (35).jpg\n","validation_pic (350).jpg\n","validation_pic (351).jpg\n","validation_pic (352).jpg\n","validation_pic (353).jpg\n","validation_pic (354).jpg\n","validation_pic (355).jpg\n","validation_pic (356).jpg\n","validation_pic (357).jpg\n","validation_pic (358).jpg\n","validation_pic (359).jpg\n","validation_pic (36).jpg\n","validation_pic (360).jpg\n","validation_pic (361).jpg\n","validation_pic (362).jpg\n","validation_pic (363).jpg\n","validation_pic (364).jpg\n","validation_pic (365).jpg\n","validation_pic (366).jpg\n","validation_pic (367).jpg\n","validation_pic (368).jpg\n","validation_pic (369).jpg\n","validation_pic (37).jpg\n","validation_pic (370).jpg\n","validation_pic (371).jpg\n","validation_pic (372).jpg\n","validation_pic (373).jpg\n","validation_pic (374).jpg\n","validation_pic (375).jpg\n","validation_pic (376).jpg\n","validation_pic (377).jpg\n","validation_pic (378).jpg\n","validation_pic (379).jpg\n","validation_pic (38).jpg\n","validation_pic (380).jpg\n","validation_pic (381).jpg\n","validation_pic (382).jpg\n","validation_pic (383).jpg\n","validation_pic (384).jpg\n","validation_pic (385).jpg\n","validation_pic (386).jpg\n","validation_pic (387).jpg\n","validation_pic (388).jpg\n","validation_pic (389).jpg\n","validation_pic (39).jpg\n","validation_pic (390).jpg\n","validation_pic (391).jpg\n","validation_pic (392).jpg\n","validation_pic (393).jpg\n","validation_pic (394).jpg\n","validation_pic (395).jpg\n","validation_pic (396).jpg\n","validation_pic (397).jpg\n","validation_pic (398).jpg\n","validation_pic (399).jpg\n","validation_pic (4).jpg\n","validation_pic (40).jpg\n","validation_pic (400).jpg\n","validation_pic (401).jpg\n","validation_pic (402).jpg\n","validation_pic (403).jpg\n","validation_pic (404).jpg\n","validation_pic (405).jpg\n","validation_pic (406).jpg\n","validation_pic (407).jpg\n","validation_pic (408).jpg\n","validation_pic (409).jpg\n","validation_pic (41).jpg\n","validation_pic (410).jpg\n","validation_pic (411).jpg\n","validation_pic (412).jpg\n","validation_pic (413).jpg\n","validation_pic (414).jpg\n","validation_pic (415).jpg\n","validation_pic (416).jpg\n","validation_pic (417).jpg\n","validation_pic (418).jpg\n","validation_pic (419).jpg\n","validation_pic (42).jpg\n","validation_pic (420).jpg\n","validation_pic (421).jpg\n","validation_pic (422).jpg\n","validation_pic (423).jpg\n","validation_pic (424).jpg\n","validation_pic (425).jpg\n","validation_pic (426).jpg\n","validation_pic (427).jpg\n","validation_pic (428).jpg\n","validation_pic (429).jpg\n","validation_pic (43).jpg\n","validation_pic (430).jpg\n","validation_pic (431).jpg\n","validation_pic (432).jpg\n","validation_pic (433).jpg\n","validation_pic (434).jpg\n","validation_pic (435).jpg\n","validation_pic (436).jpg\n","validation_pic (437).jpg\n","validation_pic (438).jpg\n","validation_pic (439).jpg\n","validation_pic (44).jpg\n","validation_pic (440).jpg\n","validation_pic (441).jpg\n","validation_pic (442).jpg\n","validation_pic (443).jpg\n","validation_pic (444).jpg\n","validation_pic (445).jpg\n","validation_pic (446).jpg\n","validation_pic (447).jpg\n","validation_pic (448).jpg\n","validation_pic (449).jpg\n","validation_pic (45).jpg\n","validation_pic (450).jpg\n","validation_pic (451).jpg\n","validation_pic (452).jpg\n","validation_pic (453).jpg\n","validation_pic (454).jpg\n","validation_pic (455).jpg\n","validation_pic (456).jpg\n","validation_pic (457).jpg\n","validation_pic (458).jpg\n","validation_pic (459).jpg\n","validation_pic (46).jpg\n","validation_pic (460).jpg\n","validation_pic (461).jpg\n","validation_pic (462).jpg\n","validation_pic (463).jpg\n","validation_pic (464).jpg\n","validation_pic (465).jpg\n","validation_pic (466).jpg\n","validation_pic (467).jpg\n","validation_pic (468).jpg\n","validation_pic (469).jpg\n","validation_pic (47).jpg\n","validation_pic (470).jpg\n","validation_pic (471).jpg\n","validation_pic (472).jpg\n","validation_pic (473).jpg\n","validation_pic (474).jpg\n","validation_pic (475).jpg\n","validation_pic (476).jpg\n","validation_pic (477).jpg\n","validation_pic (478).jpg\n","validation_pic (479).jpg\n","validation_pic (48).jpg\n","validation_pic (480).jpg\n","validation_pic (481).jpg\n","validation_pic (482).jpg\n","validation_pic (483).jpg\n","validation_pic (484).jpg\n","validation_pic (485).jpg\n","validation_pic (486).jpg\n","validation_pic (487).jpg\n","validation_pic (488).jpg\n","validation_pic (489).jpg\n","validation_pic (49).jpg\n","validation_pic (490).jpg\n","validation_pic (491).jpg\n","validation_pic (492).jpg\n","validation_pic (493).jpg\n","validation_pic (494).jpg\n","validation_pic (495).jpg\n","validation_pic (496).jpg\n","validation_pic (497).jpg\n","validation_pic (498).jpg\n","validation_pic (499).jpg\n","validation_pic (5).jpg\n","validation_pic (50).jpg\n","validation_pic (500).jpg\n","validation_pic (501).jpg\n","validation_pic (502).jpg\n","validation_pic (503).jpg\n","validation_pic (504).jpg\n","validation_pic (505).jpg\n","validation_pic (506).jpg\n","validation_pic (507).jpg\n","validation_pic (508).jpg\n","validation_pic (509).jpg\n","validation_pic (51).jpg\n","validation_pic (510).jpg\n","validation_pic (511).jpg\n","validation_pic (512).jpg\n","validation_pic (513).jpg\n","validation_pic (514).jpg\n","validation_pic (515).jpg\n","validation_pic (516).jpg\n","validation_pic (517).jpg\n","validation_pic (518).jpg\n","validation_pic (519).jpg\n","validation_pic (52).jpg\n","validation_pic (520).jpg\n","validation_pic (521).jpg\n","validation_pic (522).jpg\n","validation_pic (523).jpg\n","validation_pic (524).jpg\n","validation_pic (525).jpg\n","validation_pic (526).jpg\n","validation_pic (527).jpg\n","validation_pic (528).jpg\n","validation_pic (529).jpg\n","validation_pic (53).jpg\n","validation_pic (530).jpg\n","validation_pic (531).jpg\n","validation_pic (532).jpg\n","validation_pic (533).jpg\n","validation_pic (534).jpg\n","validation_pic (535).jpg\n","validation_pic (536).jpg\n","validation_pic (537).jpg\n","validation_pic (538).jpg\n","validation_pic (539).jpg\n","validation_pic (54).jpg\n","validation_pic (540).jpg\n","validation_pic (541).jpg\n","validation_pic (542).jpg\n","validation_pic (543).jpg\n","validation_pic (544).jpg\n","validation_pic (545).jpg\n","validation_pic (546).jpg\n","validation_pic (547).jpg\n","validation_pic (548).jpg\n","validation_pic (549).jpg\n","validation_pic (55).jpg\n","validation_pic (550).jpg\n","validation_pic (551).jpg\n","validation_pic (552).jpg\n","validation_pic (553).jpg\n","validation_pic (554).jpg\n","validation_pic (555).jpg\n","validation_pic (556).jpg\n","validation_pic (557).jpg\n","validation_pic (558).jpg\n","validation_pic (559).jpg\n","validation_pic (56).jpg\n","validation_pic (560).jpg\n","validation_pic (561).jpg\n","validation_pic (562).jpg\n","validation_pic (563).jpg\n","validation_pic (564).jpg\n","validation_pic (565).jpg\n","validation_pic (566).jpg\n","validation_pic (567).jpg\n","validation_pic (568).jpg\n","validation_pic (569).jpg\n","validation_pic (57).jpg\n","validation_pic (570).jpg\n","validation_pic (571).jpg\n","validation_pic (572).jpg\n","validation_pic (573).jpg\n","validation_pic (574).jpg\n","validation_pic (575).jpg\n","validation_pic (576).jpg\n","validation_pic (577).jpg\n","validation_pic (578).jpg\n","validation_pic (579).jpg\n","validation_pic (58).jpg\n","validation_pic (580).jpg\n","validation_pic (581).jpg\n","validation_pic (582).jpg\n","validation_pic (583).jpg\n","validation_pic (584).jpg\n","validation_pic (585).jpg\n","validation_pic (586).jpg\n","validation_pic (587).jpg\n","validation_pic (588).jpg\n","validation_pic (589).jpg\n","validation_pic (59).jpg\n","validation_pic (590).jpg\n","validation_pic (591).jpg\n","validation_pic (592).jpg\n","validation_pic (593).jpg\n","validation_pic (594).jpg\n","validation_pic (595).jpg\n","validation_pic (596).jpg\n","validation_pic (597).jpg\n","validation_pic (598).jpg\n","validation_pic (599).jpg\n","validation_pic (6).jpg\n","validation_pic (60).jpg\n","validation_pic (600).jpg\n","validation_pic (601).jpg\n","validation_pic (602).jpg\n","validation_pic (603).jpg\n","validation_pic (604).jpg\n","validation_pic (605).jpg\n","validation_pic (606).jpg\n","validation_pic (607).jpg\n","validation_pic (608).jpg\n","validation_pic (609).jpg\n","validation_pic (61).jpg\n","validation_pic (610).jpg\n","validation_pic (611).jpg\n","validation_pic (612).jpg\n","validation_pic (613).jpg\n","validation_pic (614).jpg\n","validation_pic (615).jpg\n","validation_pic (616).jpg\n","validation_pic (617).jpg\n","validation_pic (618).jpg\n","validation_pic (619).jpg\n","validation_pic (62).jpg\n","validation_pic (620).jpg\n","validation_pic (621).jpg\n","validation_pic (622).jpg\n","validation_pic (623).jpg\n","validation_pic (624).jpg\n","validation_pic (625).jpg\n","validation_pic (626).jpg\n","validation_pic (627).jpg\n","validation_pic (628).jpg\n","validation_pic (629).jpg\n","validation_pic (63).jpg\n","validation_pic (630).jpg\n","validation_pic (631).jpg\n","validation_pic (632).jpg\n","validation_pic (633).jpg\n","validation_pic (634).jpg\n","validation_pic (635).jpg\n","validation_pic (636).jpg\n","validation_pic (637).jpg\n","validation_pic (638).jpg\n","validation_pic (639).jpg\n","validation_pic (64).jpg\n","validation_pic (640).jpg\n","validation_pic (641).jpg\n","validation_pic (642).jpg\n","validation_pic (643).jpg\n","validation_pic (644).jpg\n","validation_pic (645).jpg\n","validation_pic (646).jpg\n","validation_pic (647).jpg\n","validation_pic (648).jpg\n","validation_pic (649).jpg\n","validation_pic (65).jpg\n","validation_pic (650).jpg\n","validation_pic (651).jpg\n","validation_pic (652).jpg\n","validation_pic (653).jpg\n","validation_pic (654).jpg\n","validation_pic (655).jpg\n","validation_pic (656).jpg\n","validation_pic (657).jpg\n","validation_pic (658).jpg\n","validation_pic (659).jpg\n","validation_pic (66).jpg\n","validation_pic (660).jpg\n","validation_pic (661).jpg\n","validation_pic (662).jpg\n","validation_pic (663).jpg\n","validation_pic (664).jpg\n","validation_pic (665).jpg\n","validation_pic (666).jpg\n","validation_pic (667).jpg\n","validation_pic (668).jpg\n","validation_pic (669).jpg\n","validation_pic (67).jpg\n","validation_pic (670).jpg\n","validation_pic (671).jpg\n","validation_pic (672).jpg\n","validation_pic (673).jpg\n","validation_pic (674).jpg\n","validation_pic (675).jpg\n","validation_pic (676).jpg\n","validation_pic (677).jpg\n","validation_pic (678).jpg\n","validation_pic (679).jpg\n","validation_pic (68).jpg\n","validation_pic (680).jpg\n","validation_pic (681).jpg\n","validation_pic (682).jpg\n","validation_pic (683).jpg\n","validation_pic (684).jpg\n","validation_pic (685).jpg\n","validation_pic (686).jpg\n","validation_pic (687).jpg\n","validation_pic (688).jpg\n","validation_pic (689).jpg\n","validation_pic (69).jpg\n","validation_pic (690).jpg\n","validation_pic (691).jpg\n","validation_pic (692).jpg\n","validation_pic (693).jpg\n","validation_pic (694).jpg\n","validation_pic (695).jpg\n","validation_pic (696).jpg\n","validation_pic (697).jpg\n","validation_pic (698).jpg\n","validation_pic (699).jpg\n","validation_pic (7).jpg\n","validation_pic (70).jpg\n","validation_pic (700).jpg\n","validation_pic (701).jpg\n","validation_pic (702).jpg\n","validation_pic (703).jpg\n","validation_pic (704).jpg\n","validation_pic (705).jpg\n","validation_pic (706).jpg\n","validation_pic (707).jpg\n","validation_pic (708).jpg\n","validation_pic (709).jpg\n","validation_pic (71).jpg\n","validation_pic (710).jpg\n","validation_pic (711).jpg\n","validation_pic (712).jpg\n","validation_pic (713).jpg\n","validation_pic (714).jpg\n","validation_pic (715).jpg\n","validation_pic (716).jpg\n","validation_pic (72).jpg\n","validation_pic (73).jpg\n","validation_pic (74).jpg\n","validation_pic (75).jpg\n","validation_pic (76).jpg\n","validation_pic (77).jpg\n","validation_pic (78).jpg\n","validation_pic (79).jpg\n","validation_pic (8).jpg\n","validation_pic (80).jpg\n","validation_pic (81).jpg\n","validation_pic (82).jpg\n","validation_pic (83).jpg\n","validation_pic (84).jpg\n","validation_pic (85).jpg\n","validation_pic (86).jpg\n","validation_pic (87).jpg\n","validation_pic (88).jpg\n","validation_pic (89).jpg\n","validation_pic (9).jpg\n","validation_pic (90).jpg\n","validation_pic (91).jpg\n","validation_pic (92).jpg\n","validation_pic (93).jpg\n","validation_pic (94).jpg\n","validation_pic (95).jpg\n","validation_pic (96).jpg\n","validation_pic (97).jpg\n","validation_pic (98).jpg\n","validation_pic (99).jpg\n","(716, 300, 300, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NpqzePEeLvyn","colab_type":"code","colab":{}},"source":["#Shuffle indices to get random ordering of images and classes\n","indices = np.arange(data.shape[0] )\n","np.random.shuffle(indices)\n","data, label = data[indices], label[indices]\n","#Test Train Split\n","ratio = 0.8\n","split = np.int(data.shape[0]* ratio)\n","x_train, y_train = data[:split], label[:split]\n","x_val, y_val =data[split:], label[split:]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z-RV-IYMeYRC","colab_type":"code","outputId":"6cab787f-d46a-4690-d478-27715f3bd5ec","executionInfo":{"status":"ok","timestamp":1576308503054,"user_tz":480,"elapsed":599,"user":{"displayName":"Emeri Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcxUiKuckdyRohPCkNf6AzIIN4Fo74NBwrQfHk7Q=s64","userId":"09196877081073417019"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(y_train)"],"execution_count":53,"outputs":[{"output_type":"stream","text":["[ 7 11 17 ... 11  2  6]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JfCT4moFPVDb","colab_type":"text"},"source":["Build a neural network classifier using an architecture of your choosing. This application\n","of deep learning can be done in PyTorch, TensorFlow, or a framework of your choice. This is the\n","industry standard for image classification. Describe your network and assess its performance. To\n","receive extra credit, your neural network classifier must outperform your other methods.\n","\n"]},{"cell_type":"code","metadata":{"id":"tw1zK0BkPqm1","colab_type":"code","outputId":"c7274179-e646-464f-94f8-72d248934d9c","executionInfo":{"status":"ok","timestamp":1576308505458,"user_tz":480,"elapsed":378,"user":{"displayName":"Emeri Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcxUiKuckdyRohPCkNf6AzIIN4Fo74NBwrQfHk7Q=s64","userId":"09196877081073417019"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.shape"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1501, 300, 300, 3)"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"5ZmmkoNO5ZjE","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Activation\n","from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, Convolution2D"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a9JRwl9d3O-7","colab_type":"code","colab":{}},"source":["model = Sequential() #conv - batchnorm - relu OR conv - relu - pool\n","model.add(Convolution2D(32, 3, 3, border_mode =\"same\", input_shape=(300, 300, 3)))\n","# model.add(BatchNormalization()) #GPU crash\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering='th'))\n","\n","model.add(Convolution2D(64, 2, 2, border_mode =\"same\"))\n","# model.add(BatchNormalization()) #GPU crash\n","model.add(Activation(\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2),dim_ordering='th'))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Activation(\"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(20, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4x4rW3hW4B6p","colab_type":"code","outputId":"61cedaaf-afbd-461e-d8ab-035e1512e569","executionInfo":{"status":"error","timestamp":1576308525647,"user_tz":480,"elapsed":13712,"user":{"displayName":"Emeri Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcxUiKuckdyRohPCkNf6AzIIN4Fo74NBwrQfHk7Q=s64","userId":"09196877081073417019"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\",\n","              metrics=['accuracy'])\n","model.summary()\n","\n","hist = model.fit(x_train, y_train, batch_size = 32, epochs = 10)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Model: \"sequential_10\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_19 (Conv2D)           (None, 300, 300, 32)      896       \n","_________________________________________________________________\n","activation_28 (Activation)   (None, 300, 300, 32)      0         \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 300, 150, 16)      0         \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 300, 150, 64)      4160      \n","_________________________________________________________________\n","activation_29 (Activation)   (None, 300, 150, 64)      0         \n","_________________________________________________________________\n","max_pooling2d_18 (MaxPooling (None, 300, 75, 32)       0         \n","_________________________________________________________________\n","flatten_10 (Flatten)         (None, 720000)            0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 256)               184320256 \n","_________________________________________________________________\n","activation_30 (Activation)   (None, 256)               0         \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 256)               0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 20)                5140      \n","=================================================================\n","Total params: 184,330,452\n","Trainable params: 184,330,452\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [720000,256] and type float\n\t [[{{node training_9/Adam/zeros_4}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-b8416071ff9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [720000,256] and type float\n\t [[node training_9/Adam/zeros_4 (defined at /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n\nOriginal stack trace for 'training_9/Adam/zeros_4':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-57-b8416071ff9e>\", line 5, in <module>\n    hist = model.fit(x_train, y_train, batch_size = 32, epochs = 10)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1148, in fit\n    self._make_train_function()\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 512, in _make_train_function\n    loss=self.total_loss)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 484, in get_updates\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\", line 484, in <listcomp>\n    ms = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 733, in zeros\n    v = tf.zeros(shape=shape, dtype=tf_dtype, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 2350, in zeros\n    output = fill(shape, constant(zero, dtype=dtype), name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py\", line 171, in fill\n    result = gen_array_ops.fill(dims, value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 3602, in fill\n    \"Fill\", dims=dims, value=value, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"code","metadata":{"id":"ygm6P8q8IWrj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}