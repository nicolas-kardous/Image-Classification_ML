{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDDC_JG-KYMU"
   },
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VBq0mbSVKYMX"
   },
   "source": [
    "<h2>  Part Two: Exploratory data analysis and feature extraction. </h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7A29hj1vKYMY"
   },
   "source": [
    "<h5> In this section, Compute at least 15 such image features (a method for each), including the following (NOTE: At least 10 of these must be scalar features and 2 matrix-based features): (i) image size, (ii) average of the red-channel intensity, (iii) aspectratio. This will require significant explatoratory research and data analysis. The first one is already implemented for you, and the next two are pre-specified. Additional requirements specfied in pdf. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python==3.4.2.16\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/4d/0a775b580c5a24c1d5cbb7add78312e0176101490ba26cd2e49242fa40db/opencv_contrib_python-3.4.2.16-cp37-cp37m-macosx_10_6_x86_64.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (47.9MB)\n",
      "\u001b[K     |████████████████████████████████| 47.9MB 1.5MB/s eta 0:00:011     |███████████████████▌            | 29.2MB 525kB/s eta 0:00:36     |██████████████████████▍         | 33.6MB 525kB/s eta 0:00:28\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /Users/nicolaskardous/opt/anaconda3/lib/python3.7/site-packages (from opencv-contrib-python==3.4.2.16) (1.17.2)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-3.4.2.16\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python==3.4.2.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0byNvMtkWJpw"
   },
   "outputs": [],
   "source": [
    "#Import anything you need here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "# import skimage.filter\n",
    "from skimage import filters\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.filters import prewitt_h,prewitt_v\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import gaussian\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p7OOoRE-TYA5",
    "outputId": "32ef0b6b-12dc-4cac-b1b1-460964c73085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "XgOIu5xrWJ8L",
    "outputId": "bb18b28b-2cfa-48a9-f8f8-dc9fe0b5f1e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[[[174, 190, 187], [173, 189, 186], [172, 188,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>[[[159, 129, 105], [155, 125, 99], [152, 122, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1497</td>\n",
       "      <td>[[[162, 145, 115], [164, 145, 115], [165, 146,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1498</td>\n",
       "      <td>[[[126, 155, 247], [126, 155, 247], [128, 157,...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1499</td>\n",
       "      <td>[[[10, 195, 0], [48, 255, 33], [21, 236, 44], ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1501 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image label\n",
       "0     [[[255, 255, 255], [255, 255, 255], [255, 255,...     0\n",
       "1     [[[255, 255, 255], [255, 255, 255], [255, 255,...     0\n",
       "2     [[[255, 255, 255], [255, 255, 255], [255, 255,...     0\n",
       "3     [[[174, 190, 187], [173, 189, 186], [172, 188,...     0\n",
       "4     [[[255, 255, 255], [255, 255, 255], [255, 255,...     0\n",
       "...                                                 ...   ...\n",
       "1496  [[[159, 129, 105], [155, 125, 99], [152, 122, ...    19\n",
       "1497  [[[162, 145, 115], [164, 145, 115], [165, 146,...    19\n",
       "1498  [[[126, 155, 247], [126, 155, 247], [128, 157,...    19\n",
       "1499  [[[10, 195, 0], [48, 255, 33], [21, 236, 44], ...    19\n",
       "1500  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...    19\n",
       "\n",
       "[1501 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_data = pd.read_pickle('./starting_data.pkl')\n",
    "starting_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zWs7PtDaKYMa"
   },
   "outputs": [],
   "source": [
    "def ft0(image): \n",
    "  return image.size\n",
    "\n",
    "def ft1(image): \n",
    "#Mean pixel value of red channels\n",
    "\n",
    "    feature_matrix=np.zeros((image.shape[0],image.shape[1]))\n",
    "    for i in range(0,image.shape[0]):\n",
    "      for j in range(0,image.shape[1]):\n",
    "        feature_matrix[i][j] = (int(image[i,j,0]))\n",
    "    mean_feature_matrix = np.mean(feature_matrix) \n",
    "    return mean_feature_matrix\n",
    "\n",
    "def ft2(image): #Mean pixel value of green channels\n",
    "    feature_matrix=np.zeros((image.shape[0],image.shape[1]))\n",
    "    for i in range(0,image.shape[0]):\n",
    "      for j in range(0,image.shape[1]):\n",
    "        feature_matrix[i][j] = (int(image[i,j,1]))\n",
    "    mean_feature_matrix = np.mean(feature_matrix) \n",
    "    return mean_feature_matrix\n",
    "\n",
    "def ft3(image): #Mean pixel value of blue channels\n",
    "    feature_matrix=np.zeros((image.shape[0],image.shape[1]))\n",
    "    for i in range(0,image.shape[0]):\n",
    "      for j in range(0,image.shape[1]):\n",
    "        feature_matrix[i][j] = (int(image[i,j,2]))\n",
    "    mean_feature_matrix = np.mean(feature_matrix) \n",
    "    return mean_feature_matrix\n",
    "\n",
    "def ft4(image): #Returns the aspect ratio of the image\n",
    "    return image.shape[1]/image.shape[0];\n",
    "\n",
    "# def ft5(image): #Returns SIFT (Scale Invariant Feature Transform)\n",
    "#     # Image = cv2.imread(image)\n",
    "#     Operated_Image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     sift = cv2.SIFT()\n",
    "#     kp = sift.detect(Operated_Image,None)\n",
    "#     kp, des = sift.detectAndCompute(Operated_Image,None)\n",
    "#     return [len(kp), len(des)] # kp is keypoints and des is descriptors\n",
    "\n",
    "# def ft6(image): #Returns SURF (Speeded-Up Robust Features) Speeded up version of SIFT\n",
    "# # and approximates Laplacian of Gaussian with Box Filter\n",
    "#     Image = cv2.imread(image,0)\n",
    "# # Create SURF object. You can specify params here or later.\n",
    "# # Here I set Hessian Threshold to 400\n",
    "#     surf = cv2.SURF(400)\n",
    "# # Find keypoints and descriptors directly\n",
    "#     kp, des = surf.detectAndCompute(img,None)\n",
    "#     return [len(kp), len(des)] # kp is keypoints and des is descriptors\n",
    "\n",
    "def ft7(image): #FAST Algorithm for Corner Detection\n",
    "\n",
    "    # Image = cv2.imread(image,0)\n",
    "# Initiate FAST object with default values\n",
    "    fast = cv2.FastFeatureDetector()\n",
    "# find the keypoints\n",
    "    kp = fast.detect(image,None)\n",
    "# Disable nonmaxSuppression\n",
    "    fast.setBool('nonmaxSuppression',0)\n",
    "    kp = fast.detect(image,None)\n",
    "    return len(kp)\n",
    "\n",
    "def ft8(image): #BRIEF (Binary Robust Independent Elementary Features)\n",
    "\n",
    "\n",
    "    # Image = cv2.imread(image,0)\n",
    "# Initiate STAR detector\n",
    "    star = cv2.FeatureDetector_create(\"STAR\")\n",
    "# Initiate BRIEF extractor\n",
    "    brief = cv2.DescriptorExtractor_create(\"BRIEF\")\n",
    "# find the keypoints with STAR\n",
    "    kp = star.detect(image,None)\n",
    "# compute the descriptors with BRIEF\n",
    "    kp, des = brief.compute(image, kp)\n",
    "    return [len(kp), len(des)]\n",
    "\n",
    "def ft9(image): #ORB (Oriented FAST and Rotated BRIEF)\n",
    "    # Image = cv2.imread(image,0)\n",
    "# Initiate STAR detector\n",
    "    orb = cv2.ORB()\n",
    "# find the keypoints with ORB\n",
    "    kp = orb.detect(image,None)\n",
    "# compute the descriptors with ORB\n",
    "    kp, des = orb.compute(image, kp)\n",
    "    return [len(kp),len(des)]\n",
    "\n",
    "\n",
    "def ft10(image): #Extracting Edge featuresSOURCE: https://www.analyticsvidhya.com/blog/2019/08/3-techniques-extract-features-from-image-data-machine-learning-python/\n",
    "\n",
    "    \n",
    "    gray_image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
    "    #calculating horizontal edges using prewitt kernel\n",
    "    edges_prewitt_horizontal = prewitt_h(image)\n",
    "    #calculating vertical edges using prewitt kernel\n",
    "    edges_prewitt_vertical = prewitt_v(image)\n",
    "\n",
    "    return [edges_prewitt_horizontal,edges_prewitt_vertical]\n",
    "\n",
    "def ft11(image): #Binarizing image Gray scaling is richer than Binarizing as it shows the image as a combination of different intensities of Gray. Whereas binarzing simply builds a matrix full of 0s and 1s.\n",
    "    \n",
    "    gray_image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = threshold_otsu(gray_image)\n",
    "    binary = gray_image > thresh\n",
    "    return binary # this is a matrix based feature\n",
    "\n",
    "def ft12(image):\n",
    "\n",
    "  \"\"\"\n",
    "  Blurring algorithm takes weighted average of neighbouring pixels\n",
    "  to incorporate surroundings color into every pixel. \n",
    "  \"\"\"\n",
    "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  blurred_image = skimage.filters.gaussian(gray_image,sigma=20)\n",
    "  return blurred_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def ft10(image): \n",
    "  \"\"\"\n",
    "  Brute-force matching with ORB Descriptors\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "#def ft14(image): \n",
    "  \"\"\"\n",
    "  Returns the Harris Corner Detection TODO UNSURE\n",
    "  \"\"\"\n",
    " #   Image = cv2.imread(image)\n",
    " #   Operated_Image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
    " #   Operated_Image = np.float32(Operated_Image)\n",
    " #   dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    " #   return dst \n",
    "#def ft15(image): \n",
    "  \"\"\"\n",
    " Returns Shi-Tomasi Corner Detector\n",
    "  \"\"\"\n",
    "#    Image = cv2.imread(image)\n",
    "#    Operated_Image = cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)\n",
    "#    corners = cv2.goodFeaturesToTrack(Operated_Image,25,0.01,10)\n",
    "#    corners = np.int0(corners)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99551645, 0.99494157, 0.99430577, ..., 0.99363118, 0.99430187,\n",
       "        0.99491278],\n",
       "       [0.99551788, 0.99494329, 0.99430781, ..., 0.99364527, 0.99431445,\n",
       "        0.99492398],\n",
       "       [0.99551909, 0.99494475, 0.99430956, ..., 0.99365945, 0.99432712,\n",
       "        0.99493527],\n",
       "       ...,\n",
       "       [0.98497327, 0.9830468 , 0.98091585, ..., 0.97452096, 0.97720779,\n",
       "        0.97965565],\n",
       "       [0.98498434, 0.98305937, 0.98093007, ..., 0.97451037, 0.97719834,\n",
       "        0.97964722],\n",
       "       [0.98499467, 0.98307108, 0.98094331, ..., 0.97450044, 0.97718947,\n",
       "        0.97963933]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = starting_data.loc[5]\n",
    "\n",
    "\n",
    "\n",
    "def ft12(image):\n",
    "\n",
    "  \"\"\"\n",
    "  Blurring algorithm takes weighted average of neighbouring pixels\n",
    "  to incorporate surroundings color into every pixel. \n",
    "  \"\"\"\n",
    "  gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "  blurred_image = skimage.filters.gaussian(gray_image,sigma=20)\n",
    "  return blurred_image\n",
    "\n",
    "\n",
    "ft12(temp['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqgIzqPKyFv4"
   },
   "outputs": [],
   "source": [
    "def f(data):\n",
    "    df = pd.DataFrame()\n",
    "    df['ft0'] = data.apply(lambda x: ft0(x[0]), axis = 1)\n",
    "    df['ft1'] = data.apply(lambda x: ft1(x[0]), axis = 1)\n",
    "    df['ft2'] = data.apply(lambda x: ft2(x[0]), axis = 1)\n",
    "    df['ft3'] = data.apply(lambda x: ft3(x[0]), axis = 1)\n",
    "    df['ft4'] = data.apply(lambda x: ft4(x[0]), axis = 1)\n",
    "    # df['ft5'] = data.apply(lambda x: ft5(x[0]), axis = 1)\n",
    "    # df['ft6'] = data.apply(lambda x: ft6(x[0]), axis = 1)\n",
    "    df['ft7'] = data.apply(lambda x: ft7(x[0]), axis = 1)\n",
    "    df['ft8'] = data.apply(lambda x: ft8(x[0]), axis = 1)\n",
    "    df['ft9'] = data.apply(lambda x: ft9(x[0]), axis = 1)\n",
    "    df['ft10'] = data.apply(lambda x: ft10(x[0]), axis = 1)\n",
    "    df['ft11'] = data.apply(lambda x: ft11(x[0]), axis = 1)\n",
    "    df['ft12'] = data.apply(lambda x: ft12(x[0]), axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "3CPWeqHfyKIT",
    "outputId": "cb443c1c-3bbb-4ff5-d9ce-5dd7eecc777c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7a364c805e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstarting_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'starting_data' is not defined"
     ]
    }
   ],
   "source": [
    "dat = starting_data.copy().loc[:5]\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "D1gR8SYfyQGR",
    "outputId": "9641de9b-71c5-4698-afc2-1ca9400a182f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-08451da931ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dat' is not defined"
     ]
    }
   ],
   "source": [
    "f(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pft87WxPg1i7"
   },
   "outputs": [],
   "source": [
    "# def feature_frame(df):\n",
    "    \n",
    "#     df['ft1'] = pd.Series([ft1(image) for image in df['image']])\n",
    "#     df['ft2'] = pd.Series([ft2(image) for image in df['image']])\n",
    "#     df['ft3'] = pd.Series([ft3(image) for image in df['image']])\n",
    "#     df['ft4'] = pd.Series([ft4(image) for image in df['image']])\n",
    "#     df['ft5'] = pd.Series([ft5(image) for image in df['image']])\n",
    "#     df['ft6'] = pd.Series([ft6(image) for image in df['image']])\n",
    "#     df['ft7'] = pd.Series([ft7(image) for image in df['image']])\n",
    "#     df['ft8'] = pd.Series([ft8(image) for image in df['image']])\n",
    "#     df['ft9'] = pd.Series([ft9(image) for image in df['image']])\n",
    "#     df['ft10'] = pd.Series([ft10(image) for image in df['image']])\n",
    "#     df['ft11'] = pd.Series([ft11(image) for image in df['image']])\n",
    "#     df['ft12'] = pd.Series([ft12(image) for image in df['image']])\n",
    "#     # df['ft13'] = pd.Series([ft13(image) for image in df['image']])\n",
    "#     # df['ft14'] = pd.Series([ft14(image) for image in df['image']])\n",
    "#     # df['ft15'] = pd.Series([ft15(image) for image in df['image']])\n",
    "#     # df['ft16'] = pd.Series([ft16(image) for image in df['image']])\n",
    "#     # df['ft17'] = pd.Series([ft17(image) for image in df['image']])\n",
    "#     # df['ft18'] = pd.Series([ft18(image) for image in df['image']])\n",
    "#     # df['ft19'] = pd.Series([ft19(image) for image in df['image']])\n",
    "#     # df['ft20'] = pd.Series([ft20(image) for image in df['image']])\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JwhSdc5x-BG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "np6ZRwjIg5xt",
    "outputId": "27349508-a374-4175-c150-b6d6d0126e3f"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-bb4e013f3be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-457f216e9fa1>\u001b[0m in \u001b[0;36mfeature_frame\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mft1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mft3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-457f216e9fa1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mft1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ft3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mft3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-c4cd48a520a9>\u001b[0m in \u001b[0;36mft1\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Returns the pixel size of the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mft1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Returns the average of the red-channel pictures for the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = feature_frame(starting_data)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLFQhFh3x8pd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJj7lrG7KYMl"
   },
   "source": [
    " We expect all external sources sited, and significant indication of EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kgp2OfaHKYMn"
   },
   "source": [
    "<h4> Graphs </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJCeLbiZKYMp"
   },
   "outputs": [],
   "source": [
    "# pandas function creates a report from several common EDA commands\n",
    "def eda(dataframe):\n",
    " print(“missing values: {}”.format(dataframe.isnull().sum()))\n",
    " print(“dataframe index: {}”.format(dataframe.index))\n",
    " print(“dataframe types: {}”.format(dataframe.dtypes))\n",
    " print(“dataframe shape: {}”.format(dataframe.shape))\n",
    " print(“dataframe describe: {}”.format(dataframe.describe()))\n",
    "for item in dataframe:\n",
    " print(item)\n",
    " print(dataframe[item].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "zgyzjytpglnW",
    "outputId": "34156985-8b5f-4516-d022-c96236e447ca"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f1b4e991e3d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Add a title and show the plot.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Missing Values Per Column'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create tick mark labels on the Y axis and rotate them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'skimage.data' has no attribute 'isnull'"
     ]
    }
   ],
   "source": [
    "# plot missing data:\n",
    "data.isnull().sum().plot(kind='bar')\n",
    "# Add a title and show the plot.\n",
    "plt.title('Number of Missing Values Per Column')\n",
    "# Create tick mark labels on the Y axis and rotate them.\n",
    "plt.xticks(rotation = 45)\n",
    "# Create X axis label.\n",
    "plt.xlabel(\"Columns\")\n",
    "# Create Y axis label.\n",
    "plt.ylabel(\"NaN Values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dp5y4Z6wKYMs"
   },
   "source": [
    "<h4> Sources </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vZ3KmkFegaZU"
   },
   "source": [
    "https://medium.com/swlh/eda-exploratory-data-analysis-e0f453d97894"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aU7l5LHiKYMy"
   },
   "source": [
    "<h4> DataFrame Creation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftrOJZz_KYMz"
   },
   "outputs": [],
   "source": [
    "def feature_frame(df):\n",
    "    return df\n",
    "    #Returns data-frame with all the features now inside, and calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "l2xPwZUxKYM2",
    "outputId": "42a10c29-aa37-43ac-86aa-f44640a1750e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-87bdb7e363c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_from_nb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_from_nb1' is not defined"
     ]
    }
   ],
   "source": [
    "feature_frame(starting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiYf-Ux-dJG_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GradProject_NB2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
