{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RtIChpaQYZ2H"
   },
   "source": [
    "\n",
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUDeHBW9-mP0"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pp1l3_bfAD2C"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_std</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_std</th>\n",
       "      <th>luminance_mean</th>\n",
       "      <th>luminance_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sift_kp</th>\n",
       "      <th>surf_kp</th>\n",
       "      <th>canny_edges</th>\n",
       "      <th>prewitt_h</th>\n",
       "      <th>prewitt_v</th>\n",
       "      <th>binarize</th>\n",
       "      <th>harris</th>\n",
       "      <th>shi_tomasi</th>\n",
       "      <th>label</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>195816</td>\n",
       "      <td>2.426829</td>\n",
       "      <td>183.355727</td>\n",
       "      <td>56.406650</td>\n",
       "      <td>176.750337</td>\n",
       "      <td>64.039966</td>\n",
       "      <td>149.151581</td>\n",
       "      <td>79.648356</td>\n",
       "      <td>166.791454</td>\n",
       "      <td>53.495949</td>\n",
       "      <td>...</td>\n",
       "      <td>340</td>\n",
       "      <td>266</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[205, 203, 164], [205, 203, 162], [226, 223, ...</td>\n",
       "      <td>[[[166, 116]], [[366, 72]], [[89, 128]], [[59,...</td>\n",
       "      <td>0</td>\n",
       "      <td>airplanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>221352</td>\n",
       "      <td>2.179348</td>\n",
       "      <td>210.739822</td>\n",
       "      <td>55.293247</td>\n",
       "      <td>189.280101</td>\n",
       "      <td>74.486619</td>\n",
       "      <td>164.805242</td>\n",
       "      <td>70.417988</td>\n",
       "      <td>181.672576</td>\n",
       "      <td>56.847182</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>203</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[244, 203, 185], [240, 181, 163], [242, 179, ...</td>\n",
       "      <td>[[[324, 87]], [[61, 72]], [[311, 116]], [[238,...</td>\n",
       "      <td>0</td>\n",
       "      <td>airplanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>194535</td>\n",
       "      <td>2.381818</td>\n",
       "      <td>170.123787</td>\n",
       "      <td>64.391428</td>\n",
       "      <td>147.788681</td>\n",
       "      <td>68.085443</td>\n",
       "      <td>111.753798</td>\n",
       "      <td>89.914294</td>\n",
       "      <td>145.131762</td>\n",
       "      <td>56.089846</td>\n",
       "      <td>...</td>\n",
       "      <td>466</td>\n",
       "      <td>317</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[208, 221, 237], [188, 201, 217], [160, 173, ...</td>\n",
       "      <td>[[[319, 72]], [[286, 74]], [[165, 92]], [[296,...</td>\n",
       "      <td>0</td>\n",
       "      <td>airplanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>200430</td>\n",
       "      <td>2.311765</td>\n",
       "      <td>152.159752</td>\n",
       "      <td>64.525514</td>\n",
       "      <td>132.648316</td>\n",
       "      <td>62.769907</td>\n",
       "      <td>77.917303</td>\n",
       "      <td>83.412773</td>\n",
       "      <td>129.573314</td>\n",
       "      <td>53.570175</td>\n",
       "      <td>...</td>\n",
       "      <td>575</td>\n",
       "      <td>382</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[226, 209, 191], [212, 195, 177], [192, 174, ...</td>\n",
       "      <td>[[[52, 93]], [[69, 81]], [[264, 65]], [[297, 6...</td>\n",
       "      <td>0</td>\n",
       "      <td>airplanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>208560</td>\n",
       "      <td>2.244318</td>\n",
       "      <td>147.397886</td>\n",
       "      <td>73.855439</td>\n",
       "      <td>150.504790</td>\n",
       "      <td>71.385855</td>\n",
       "      <td>86.252963</td>\n",
       "      <td>94.391311</td>\n",
       "      <td>138.168607</td>\n",
       "      <td>62.001119</td>\n",
       "      <td>...</td>\n",
       "      <td>592</td>\n",
       "      <td>431</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[214, 217, 200], [234, 237, 220], [255, 255, ...</td>\n",
       "      <td>[[[97, 71]], [[136, 9]], [[107, 6]], [[153, 90...</td>\n",
       "      <td>0</td>\n",
       "      <td>airplanes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1496</td>\n",
       "      <td>396000</td>\n",
       "      <td>1.212121</td>\n",
       "      <td>114.709068</td>\n",
       "      <td>64.511973</td>\n",
       "      <td>95.834561</td>\n",
       "      <td>58.310344</td>\n",
       "      <td>75.434515</td>\n",
       "      <td>53.332933</td>\n",
       "      <td>101.154443</td>\n",
       "      <td>50.642540</td>\n",
       "      <td>...</td>\n",
       "      <td>1225</td>\n",
       "      <td>1105</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[49, 28, 37], [3, 6, 13], [1, 21, 30], [1, 18...</td>\n",
       "      <td>[[[279, 229]], [[270, 178]], [[224, 207]], [[2...</td>\n",
       "      <td>19</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1497</td>\n",
       "      <td>1089906</td>\n",
       "      <td>1.531828</td>\n",
       "      <td>137.932059</td>\n",
       "      <td>62.316716</td>\n",
       "      <td>121.621978</td>\n",
       "      <td>54.696420</td>\n",
       "      <td>104.218482</td>\n",
       "      <td>48.823939</td>\n",
       "      <td>122.936149</td>\n",
       "      <td>47.968545</td>\n",
       "      <td>...</td>\n",
       "      <td>2891</td>\n",
       "      <td>3268</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[159, 138, 107], [166, 143, 102], [140, 114, ...</td>\n",
       "      <td>[[[77, 202]], [[450, 220]], [[593, 162]], [[39...</td>\n",
       "      <td>19</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1498</td>\n",
       "      <td>337500</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>122.369742</td>\n",
       "      <td>54.019985</td>\n",
       "      <td>116.308462</td>\n",
       "      <td>55.000331</td>\n",
       "      <td>117.038729</td>\n",
       "      <td>72.385317</td>\n",
       "      <td>117.516407</td>\n",
       "      <td>47.401735</td>\n",
       "      <td>...</td>\n",
       "      <td>1713</td>\n",
       "      <td>1144</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[165, 150, 193], [156, 143, 186], [114, 101, ...</td>\n",
       "      <td>[[[101, 282]], [[76, 284]], [[116, 288]], [[22...</td>\n",
       "      <td>19</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1499</td>\n",
       "      <td>72468</td>\n",
       "      <td>1.386364</td>\n",
       "      <td>111.124690</td>\n",
       "      <td>64.523423</td>\n",
       "      <td>119.316857</td>\n",
       "      <td>62.696222</td>\n",
       "      <td>98.854943</td>\n",
       "      <td>58.885573</td>\n",
       "      <td>114.365130</td>\n",
       "      <td>50.608024</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>309</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[[62, 255, 52], [101, 255, 95], [17, 211, 16],...</td>\n",
       "      <td>[[[46, 25]], [[32, 46]], [[64, 31]], [[146, 12...</td>\n",
       "      <td>19</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>322608</td>\n",
       "      <td>1.314685</td>\n",
       "      <td>140.480797</td>\n",
       "      <td>91.552303</td>\n",
       "      <td>127.001051</td>\n",
       "      <td>86.037327</td>\n",
       "      <td>90.226296</td>\n",
       "      <td>77.865047</td>\n",
       "      <td>124.932466</td>\n",
       "      <td>73.378385</td>\n",
       "      <td>...</td>\n",
       "      <td>1349</td>\n",
       "      <td>1189</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[172, 174, 163], [105, 107, 93], [128, 131, 1...</td>\n",
       "      <td>[[[109, 101]], [[191, 72]], [[119, 92]], [[130...</td>\n",
       "      <td>19</td>\n",
       "      <td>zebra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1501 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         size  aspect_ratio      r_mean      r_std      g_mean      g_std  \\\n",
       "0      195816      2.426829  183.355727  56.406650  176.750337  64.039966   \n",
       "1      221352      2.179348  210.739822  55.293247  189.280101  74.486619   \n",
       "2      194535      2.381818  170.123787  64.391428  147.788681  68.085443   \n",
       "3      200430      2.311765  152.159752  64.525514  132.648316  62.769907   \n",
       "4      208560      2.244318  147.397886  73.855439  150.504790  71.385855   \n",
       "...       ...           ...         ...        ...         ...        ...   \n",
       "1496   396000      1.212121  114.709068  64.511973   95.834561  58.310344   \n",
       "1497  1089906      1.531828  137.932059  62.316716  121.621978  54.696420   \n",
       "1498   337500      1.250000  122.369742  54.019985  116.308462  55.000331   \n",
       "1499    72468      1.386364  111.124690  64.523423  119.316857  62.696222   \n",
       "1500   322608      1.314685  140.480797  91.552303  127.001051  86.037327   \n",
       "\n",
       "          b_mean      b_std  luminance_mean  luminance_std  ...  sift_kp  \\\n",
       "0     149.151581  79.648356      166.791454      53.495949  ...      340   \n",
       "1     164.805242  70.417988      181.672576      56.847182  ...      207   \n",
       "2     111.753798  89.914294      145.131762      56.089846  ...      466   \n",
       "3      77.917303  83.412773      129.573314      53.570175  ...      575   \n",
       "4      86.252963  94.391311      138.168607      62.001119  ...      592   \n",
       "...          ...        ...             ...            ...  ...      ...   \n",
       "1496   75.434515  53.332933      101.154443      50.642540  ...     1225   \n",
       "1497  104.218482  48.823939      122.936149      47.968545  ...     2891   \n",
       "1498  117.038729  72.385317      117.516407      47.401735  ...     1713   \n",
       "1499   98.854943  58.885573      114.365130      50.608024  ...      207   \n",
       "1500   90.226296  77.865047      124.932466      73.378385  ...     1349   \n",
       "\n",
       "      surf_kp                                        canny_edges  \\\n",
       "0         266  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1         203  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2         317  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "3         382  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "4         431  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "...       ...                                                ...   \n",
       "1496     1105  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1497     3268  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1498     1144  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1499      309  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1500     1189  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                              prewitt_h  \\\n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                 ...   \n",
       "1496  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1497  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1498  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1499  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1500  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                              prewitt_v  \\\n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "...                                                 ...   \n",
       "1496  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1497  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1498  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1499  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1500  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                               binarize  \\\n",
       "0     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "2     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "3     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "4     [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "...                                                 ...   \n",
       "1496  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1497  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1498  [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1499  [[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...   \n",
       "1500  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                                 harris  \\\n",
       "0     [[205, 203, 164], [205, 203, 162], [226, 223, ...   \n",
       "1     [[244, 203, 185], [240, 181, 163], [242, 179, ...   \n",
       "2     [[208, 221, 237], [188, 201, 217], [160, 173, ...   \n",
       "3     [[226, 209, 191], [212, 195, 177], [192, 174, ...   \n",
       "4     [[214, 217, 200], [234, 237, 220], [255, 255, ...   \n",
       "...                                                 ...   \n",
       "1496  [[49, 28, 37], [3, 6, 13], [1, 21, 30], [1, 18...   \n",
       "1497  [[159, 138, 107], [166, 143, 102], [140, 114, ...   \n",
       "1498  [[165, 150, 193], [156, 143, 186], [114, 101, ...   \n",
       "1499  [[62, 255, 52], [101, 255, 95], [17, 211, 16],...   \n",
       "1500  [[172, 174, 163], [105, 107, 93], [128, 131, 1...   \n",
       "\n",
       "                                             shi_tomasi  label categories  \n",
       "0     [[[166, 116]], [[366, 72]], [[89, 128]], [[59,...      0  airplanes  \n",
       "1     [[[324, 87]], [[61, 72]], [[311, 116]], [[238,...      0  airplanes  \n",
       "2     [[[319, 72]], [[286, 74]], [[165, 92]], [[296,...      0  airplanes  \n",
       "3     [[[52, 93]], [[69, 81]], [[264, 65]], [[297, 6...      0  airplanes  \n",
       "4     [[[97, 71]], [[136, 9]], [[107, 6]], [[153, 90...      0  airplanes  \n",
       "...                                                 ...    ...        ...  \n",
       "1496  [[[279, 229]], [[270, 178]], [[224, 207]], [[2...     19      zebra  \n",
       "1497  [[[77, 202]], [[450, 220]], [[593, 162]], [[39...     19      zebra  \n",
       "1498  [[[101, 282]], [[76, 284]], [[116, 288]], [[22...     19      zebra  \n",
       "1499  [[[46, 25]], [[32, 46]], [[64, 31]], [[146, 12...     19      zebra  \n",
       "1500  [[[109, 101]], [[191, 72]], [[119, 92]], [[130...     19      zebra  \n",
       "\n",
       "[1501 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_data = pd.read_pickle('./features_labeled.pkl')\n",
    "starting_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=starting_data.drop(columns=['categories'])\n",
    "label = starting_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(starting_data)):\n",
    "        data['canny_edges'][i]=data['canny_edges'][i].flatten()\n",
    "for i in range(0,len(starting_data)):\n",
    "        data['prewitt_h'][i]=data['prewitt_h'][i].flatten()\n",
    "for i in range(0,len(starting_data)):\n",
    "        data['prewitt_v'][i]=data['prewitt_v'][i].flatten()\n",
    "for i in range(0,len(starting_data)):\n",
    "        data['binarize'][i]=data['binarize'][i].flatten()\n",
    "for i in range(0,len(starting_data)):\n",
    "        data['harris'][i]=data['harris'][i].flatten()\n",
    "for i in range(0,len(starting_data)):\n",
    "        data['shi_tomasi'][i]=data['shi_tomasi'][i].flatten()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.copy()\n",
    "new_data['canny_edges']=new_data['canny_edges'].apply(lambda x: sum(x))\n",
    "new_data['prewitt_h']=new_data['prewitt_h'].apply(lambda x: sum(x))\n",
    "new_data['prewitt_v']=new_data['prewitt_v'].apply(lambda x: sum(x))\n",
    "new_data['binarize']=new_data['binarize'].apply(lambda x: np.mean(x))\n",
    "new_data['harris']=new_data['harris'].apply(lambda x: np.mean(x))\n",
    "new_data['shi_tomasi']=new_data['shi_tomasi'].apply(lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>r_std</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>g_std</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>b_std</th>\n",
       "      <th>luminance_mean</th>\n",
       "      <th>luminance_std</th>\n",
       "      <th>...</th>\n",
       "      <th>orb</th>\n",
       "      <th>sift_kp</th>\n",
       "      <th>surf_kp</th>\n",
       "      <th>canny_edges</th>\n",
       "      <th>prewitt_h</th>\n",
       "      <th>prewitt_v</th>\n",
       "      <th>binarize</th>\n",
       "      <th>harris</th>\n",
       "      <th>shi_tomasi</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>195816</td>\n",
       "      <td>2.426829</td>\n",
       "      <td>183.355727</td>\n",
       "      <td>56.406650</td>\n",
       "      <td>176.750337</td>\n",
       "      <td>64.039966</td>\n",
       "      <td>149.151581</td>\n",
       "      <td>79.648356</td>\n",
       "      <td>166.791454</td>\n",
       "      <td>53.495949</td>\n",
       "      <td>...</td>\n",
       "      <td>398</td>\n",
       "      <td>340</td>\n",
       "      <td>266</td>\n",
       "      <td>3819</td>\n",
       "      <td>-194.894118</td>\n",
       "      <td>4.385381e-15</td>\n",
       "      <td>0.513160</td>\n",
       "      <td>121.392454</td>\n",
       "      <td>125.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>221352</td>\n",
       "      <td>2.179348</td>\n",
       "      <td>210.739822</td>\n",
       "      <td>55.293247</td>\n",
       "      <td>189.280101</td>\n",
       "      <td>74.486619</td>\n",
       "      <td>164.805242</td>\n",
       "      <td>70.417988</td>\n",
       "      <td>181.672576</td>\n",
       "      <td>56.847182</td>\n",
       "      <td>...</td>\n",
       "      <td>413</td>\n",
       "      <td>207</td>\n",
       "      <td>203</td>\n",
       "      <td>1817</td>\n",
       "      <td>-34.841830</td>\n",
       "      <td>-1.143882e+02</td>\n",
       "      <td>0.842771</td>\n",
       "      <td>115.469323</td>\n",
       "      <td>160.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>194535</td>\n",
       "      <td>2.381818</td>\n",
       "      <td>170.123787</td>\n",
       "      <td>64.391428</td>\n",
       "      <td>147.788681</td>\n",
       "      <td>68.085443</td>\n",
       "      <td>111.753798</td>\n",
       "      <td>89.914294</td>\n",
       "      <td>145.131762</td>\n",
       "      <td>56.089846</td>\n",
       "      <td>...</td>\n",
       "      <td>392</td>\n",
       "      <td>466</td>\n",
       "      <td>317</td>\n",
       "      <td>3755</td>\n",
       "      <td>178.556863</td>\n",
       "      <td>3.996803e-14</td>\n",
       "      <td>0.227126</td>\n",
       "      <td>93.911721</td>\n",
       "      <td>142.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>200430</td>\n",
       "      <td>2.311765</td>\n",
       "      <td>152.159752</td>\n",
       "      <td>64.525514</td>\n",
       "      <td>132.648316</td>\n",
       "      <td>62.769907</td>\n",
       "      <td>77.917303</td>\n",
       "      <td>83.412773</td>\n",
       "      <td>129.573314</td>\n",
       "      <td>53.570175</td>\n",
       "      <td>...</td>\n",
       "      <td>396</td>\n",
       "      <td>575</td>\n",
       "      <td>382</td>\n",
       "      <td>5270</td>\n",
       "      <td>-252.338562</td>\n",
       "      <td>2.062941e+02</td>\n",
       "      <td>0.212932</td>\n",
       "      <td>110.053966</td>\n",
       "      <td>126.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>208560</td>\n",
       "      <td>2.244318</td>\n",
       "      <td>147.397886</td>\n",
       "      <td>73.855439</td>\n",
       "      <td>150.504790</td>\n",
       "      <td>71.385855</td>\n",
       "      <td>86.252963</td>\n",
       "      <td>94.391311</td>\n",
       "      <td>138.168607</td>\n",
       "      <td>62.001119</td>\n",
       "      <td>...</td>\n",
       "      <td>407</td>\n",
       "      <td>592</td>\n",
       "      <td>431</td>\n",
       "      <td>4616</td>\n",
       "      <td>-380.200000</td>\n",
       "      <td>-2.003953e-14</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>114.599032</td>\n",
       "      <td>99.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size  aspect_ratio      r_mean      r_std      g_mean      g_std  \\\n",
       "0  195816      2.426829  183.355727  56.406650  176.750337  64.039966   \n",
       "1  221352      2.179348  210.739822  55.293247  189.280101  74.486619   \n",
       "2  194535      2.381818  170.123787  64.391428  147.788681  68.085443   \n",
       "3  200430      2.311765  152.159752  64.525514  132.648316  62.769907   \n",
       "4  208560      2.244318  147.397886  73.855439  150.504790  71.385855   \n",
       "\n",
       "       b_mean      b_std  luminance_mean  luminance_std  ...  orb  sift_kp  \\\n",
       "0  149.151581  79.648356      166.791454      53.495949  ...  398      340   \n",
       "1  164.805242  70.417988      181.672576      56.847182  ...  413      207   \n",
       "2  111.753798  89.914294      145.131762      56.089846  ...  392      466   \n",
       "3   77.917303  83.412773      129.573314      53.570175  ...  396      575   \n",
       "4   86.252963  94.391311      138.168607      62.001119  ...  407      592   \n",
       "\n",
       "   surf_kp  canny_edges   prewitt_h     prewitt_v  binarize      harris  \\\n",
       "0      266         3819 -194.894118  4.385381e-15  0.513160  121.392454   \n",
       "1      203         1817  -34.841830 -1.143882e+02  0.842771  115.469323   \n",
       "2      317         3755  178.556863  3.996803e-14  0.227126   93.911721   \n",
       "3      382         5270 -252.338562  2.062941e+02  0.212932  110.053966   \n",
       "4      431         4616 -380.200000 -2.003953e-14  0.247828  114.599032   \n",
       "\n",
       "   shi_tomasi  label  \n",
       "0      125.92      0  \n",
       "1      160.38      0  \n",
       "2      142.00      0  \n",
       "3      126.54      0  \n",
       "4       99.30      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xucd0v0EYZ2Q"
   },
   "outputs": [],
   "source": [
    "# def train_test_split(df):\n",
    "#     df_new = df.copy\n",
    "#     df_new = df_new.drop(columns=['label'])\n",
    "#     ss= StandardScaler()\n",
    "#     df_stand = ss.fit_transform(df_new.values)\n",
    "#     X= df_stand\n",
    "#     y = df['label'].values\n",
    "#     X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "#         X, y, test_size=0.2, random_state=42)\n",
    "#     y_train=y_train.astype('int')\n",
    "#     y_test = y_test.astype('int')\n",
    "#     return X_train, X_test, y_train, y_test\n",
    "# #Split the data into a training set, and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = new_data.copy()\n",
    "transform_data=transform_data.drop(columns=['label'])\n",
    "ss= StandardScaler()\n",
    "data_stand = ss.fit_transform(transform_data.values)\n",
    "X = data_stand\n",
    "y = new_data['label'].values\n",
    "y=y.astype('int')\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.59766714e-01, -1.34397851e+00, -1.40375374e-01, ...,\n",
       "         -7.95876110e-04, -9.84528172e-01,  1.83459156e+00],\n",
       "        [-2.39943666e-01,  5.34882818e-01, -6.05972230e-01, ...,\n",
       "         -8.13956677e-01,  1.39668483e-01, -8.29697140e-01],\n",
       "        [ 2.80111069e-01,  6.48535295e-01,  3.13392589e-01, ...,\n",
       "         -3.18163592e-01,  5.98655666e-01,  6.37191173e-01],\n",
       "        ...,\n",
       "        [ 6.06802507e-02, -9.06880034e-01, -4.61506049e-01, ...,\n",
       "          3.88384079e-01,  4.84546853e-01,  8.75329239e-02],\n",
       "        [-3.80091086e-01,  3.32256687e-01,  1.68092110e+00, ...,\n",
       "          1.43921140e+00,  1.44276959e+00, -7.73048027e-01],\n",
       "        [ 2.31321285e-01,  1.45217182e-01,  1.39692215e-01, ...,\n",
       "         -7.57585873e-01, -8.90232311e-01,  5.25673348e-01]]),\n",
       " array([[-0.14351916, -1.37502762, -0.75682154, ..., -0.22483742,\n",
       "         -0.69089385, -0.2768018 ],\n",
       "        [-0.17731368,  0.40405645, -0.01903368, ...,  0.15332702,\n",
       "          0.66150739, -0.2646627 ],\n",
       "        [-0.29490404,  0.44069823,  0.27326387, ..., -0.38237893,\n",
       "         -1.29363022, -0.56830195],\n",
       "        ...,\n",
       "        [ 0.32680634,  0.14521718, -0.7073658 , ..., -0.59527887,\n",
       "         -0.93614756,  0.56370918],\n",
       "        [ 0.32680634, -1.21861254,  0.22987677, ..., -0.26617535,\n",
       "          1.19212384,  0.51143014],\n",
       "        [ 0.61278922, -1.17023479,  2.2745421 , ...,  1.86471101,\n",
       "          0.83033218,  0.46465416]]),\n",
       " array([ 8, 15, 14, ..., 11, 19, 14]),\n",
       " array([14,  9,  6,  6,  6,  8, 18, 17, 18,  3, 12, 18, 10, 18,  0, 16, 19,\n",
       "        16,  6,  0, 19, 13, 15, 16, 14,  6, 19, 19, 10, 17, 18, 14, 19, 11,\n",
       "         3,  4,  6,  6, 19,  0, 13,  6, 19, 11, 14,  5,  5,  4,  9, 10, 15,\n",
       "         8, 14, 15, 18,  9,  0,  7,  4, 12, 12,  8,  7,  0, 11,  7,  4, 10,\n",
       "        16,  2,  4, 14, 10,  4,  9,  9, 14,  7,  6, 12, 18,  0,  3, 10, 11,\n",
       "         0,  8, 11, 13, 15,  8,  3,  3, 18, 13,  6,  6,  1, 14,  5, 12, 13,\n",
       "        10, 14,  7,  0,  0, 12,  0, 12,  6,  9,  9,  3,  1,  6, 10,  2,  1,\n",
       "        14, 12, 16,  9,  6,  1, 15, 10,  9, 13,  6,  9,  0, 13, 15, 19,  0,\n",
       "         7,  5, 13,  3, 13,  3,  9,  3, 16, 12, 13,  9,  4, 11, 12, 14, 14,\n",
       "        19,  7, 17, 12,  2,  5,  0,  6,  5, 13, 14,  1,  1, 19, 13, 14,  5,\n",
       "         3, 19,  7,  9,  1,  3,  9, 17,  7, 14,  3,  8,  2,  0,  9, 19, 13,\n",
       "         5, 13,  8,  9, 17,  9, 16, 12,  2, 12,  4, 10,  5, 10,  8,  6,  6,\n",
       "        15, 12,  2, 11,  5, 11,  0, 19,  8, 12,  3,  4, 10,  6,  9,  2,  8,\n",
       "        11, 11, 14,  3,  6,  0,  0, 15, 13, 13,  6, 18, 17, 13, 11, 14, 15,\n",
       "        13, 19,  9, 13, 11,  1,  7,  7, 17,  9, 16, 19, 17,  3,  9, 16,  9,\n",
       "        13,  5,  8, 12, 14, 11,  3,  8, 12, 19, 10,  8,  3, 10, 12,  5,  0,\n",
       "         4,  8, 17, 16,  9, 15,  5, 11, 15, 14, 15,  9,  3,  8,  2, 16,  1,\n",
       "        18,  8, 14,  1, 16, 10, 12,  8, 17,  9,  9,  5]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3Fcba6hYZ2M"
   },
   "source": [
    "<h2>  Part Three: Classifier training and performance assessment. </h2>\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7q_7-WzYZ2a"
   },
   "source": [
    "<h3>  Train models using all of the following methods below. Be sure to drop the actual image column, and the encoding</h3>\tTake note of the differences in accuracy, and methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7wu-wGzYZ2c"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_LR_accuracy(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 5 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the accuracy on that subset (the validation set)\n",
    "    Return the average MSE of these 5 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation accuracy for the 5 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=5)\n",
    "    validation_accuracy = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = X_train[train_idx] , X_train[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train[train_idx] , Y_train[valid_idx]\n",
    "        # Fit the model on the training split\n",
    "        Logistic_Regression.fit(split_X_train, split_Y_train)\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        accuracy = accuracy_score(split_Y_valid, model.predict(split_X_valid))\n",
    "\n",
    "\n",
    "        validation_accuracy.append(accuracy)\n",
    "        \n",
    "    return np.mean(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t9OJbvqVYZ2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying first 1 features\n",
      "\tAccuracy: 0.15750000000000003\n",
      "Trying first 2 features\n",
      "\tAccuracy: 0.20916666666666667\n",
      "Trying first 3 features\n",
      "\tAccuracy: 0.2633333333333333\n",
      "Trying first 4 features\n",
      "\tAccuracy: 0.2641666666666667\n",
      "Trying first 5 features\n",
      "\tAccuracy: 0.2883333333333333\n",
      "Trying first 6 features\n",
      "\tAccuracy: 0.30249999999999994\n",
      "Trying first 7 features\n",
      "\tAccuracy: 0.32\n",
      "Trying first 8 features\n",
      "\tAccuracy: 0.3275\n",
      "Trying first 9 features\n",
      "\tAccuracy: 0.3283333333333333\n",
      "Trying first 10 features\n",
      "\tAccuracy: 0.3325\n",
      "Trying first 11 features\n",
      "\tAccuracy: 0.33166666666666667\n",
      "Trying first 12 features\n",
      "\tAccuracy: 0.3441666666666667\n",
      "Trying first 13 features\n",
      "\tAccuracy: 0.3441666666666666\n",
      "Trying first 14 features\n",
      "\tAccuracy: 0.35833333333333334\n",
      "Trying first 15 features\n",
      "\tAccuracy: 0.36500000000000005\n",
      "Trying first 16 features\n",
      "\tAccuracy: 0.3625\n",
      "Trying first 17 features\n",
      "\tAccuracy: 0.36333333333333334\n",
      "Trying first 18 features\n",
      "\tAccuracy: 0.36416666666666664\n",
      "Trying first 19 features\n",
      "\tAccuracy: 0.37249999999999994\n",
      "Trying first 20 features\n",
      "\tAccuracy: 0.37750000000000006\n",
      "Trying first 21 features\n",
      "\tAccuracy: 0.37499999999999994\n",
      "Trying first 22 features\n",
      "\tAccuracy: 0.37499999999999994\n",
      "Trying first 23 features\n",
      "\tAccuracy: 0.37583333333333335\n",
      "Trying first 24 features\n",
      "\tAccuracy: 0.38416666666666666\n",
      "Trying first 25 features\n",
      "\tAccuracy: 0.38833333333333336\n",
      "Logistic Regression best number of features 25\n",
      "KFold Validation Accuracy 0.38833333333333336\n",
      "Logistic Regression Test Accuracy 0.38870431893687707\n",
      "Minimum increase in accuracy is from features:  [20, 21]\n"
     ]
    }
   ],
   "source": [
    "Logistic_Regression = LogisticRegression()\n",
    "\n",
    "def compute_LR_accuracy(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 5 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the accuracy on that subset (the validation set)\n",
    "    Return the average MSE of these 5 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation accuracy for the 5 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=5)\n",
    "    validation_accuracy_LR = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = X_train[train_idx] , X_train[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train[train_idx] , Y_train[valid_idx]\n",
    "        # Fit the model on the training split\n",
    "        Logistic_Regression.fit(split_X_train, split_Y_train)\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        accuracy = accuracy_score(split_Y_valid, Logistic_Regression.predict(split_X_valid))\n",
    "\n",
    "\n",
    "        validation_accuracy_LR.append(accuracy)\n",
    "        \n",
    "    return np.mean(validation_accuracy_LR)\n",
    "    \n",
    "\n",
    "#Use compute_LR_accuracy to determine how many of the first ùëÅ features we should use to get the highest\n",
    "\n",
    "range_of_num_features = range(1,X_train.shape[1]+1)\n",
    "\n",
    "accuracy_LR=[]\n",
    "\n",
    "for N in range_of_num_features:\n",
    "    print(f\"Trying first {N} features\")\n",
    "    model_LR = Logistic_Regression\n",
    "    \n",
    "    # compute the cross validation accuracy\n",
    "    accuracy = compute_LR_accuracy(model_LR, X_train[:,:N],y_train)\n",
    "    \n",
    "    print(\"\\tAccuracy:\", accuracy)\n",
    "    accuracy_LR.append(accuracy)\n",
    "\n",
    "\n",
    "best_num_features_LR = np.argmax(accuracy_LR) + 1\n",
    "best_accuracy_LR = accuracy_LR[best_num_features_LR-1]\n",
    "\n",
    "# Fit Logistic Regression Model\n",
    "Logistic_Regression.fit(X_train[:, :best_num_features_LR], y_train)\n",
    "\n",
    "# Predict points from the test set and calculate the accuracy\n",
    "test_accuracy_LR = accuracy_score(y_test, Logistic_Regression.predict(X_test[:, :best_num_features_LR]))\n",
    "\n",
    "# Minimum increase in accuracy\n",
    "diff, index = findMinDiff(accuracy_LR)\n",
    "\n",
    "print(\"Logistic Regression best number of features\", best_num_features_LR)\n",
    "print(\"KFold Validation Accuracy\", best_accuracy_LR)\n",
    "print(\"Logistic Regression Test Accuracy\", test_accuracy_LR)\n",
    "print(\"Minimum increase in accuracy is from features: \", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum increase in accuracy\n",
    "\n",
    "def findMinDiff(arr): \n",
    "    # Initialize difference as infinite \n",
    "    diff = 10**20\n",
    "      \n",
    "    # Find the min diff by comparing difference \n",
    "    # of all possible pairs in given array \n",
    "    for i in range(0,len(arr)): \n",
    "        for j in range(i+1,len(arr)): \n",
    "            if abs(accuracy_LR[i]-accuracy_LR[j]) < diff: \n",
    "                diff = abs(accuracy_LR[i] - accuracy_LR[j]) \n",
    "                index = [i,j]\n",
    "  \n",
    "    # Return min diff \n",
    "    return diff, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7W_gGWdXYZ2k"
   },
   "source": [
    "<h3>K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i3haTmQOYZ2m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.17910448, 0.3015873 , 0.38333333, 0.31578947, 0.22222222]),\n",
       " 0.38205980066445183)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train, y_train)\n",
    "neigh_predict = neigh.predict(X_test)\n",
    "scores_KNN = cross_val_score(neigh, X_test, y_test, cv=5)\n",
    "scores_KNN, accuracy_score(y_test,neigh_predict),\n",
    "#scores_KNN\n",
    "#y_pred_KNN=neigh.predict(X_test)\n",
    "#accuracy_score(y_test,y_pred_KNN)\n",
    "\n",
    "Logistic_Regression = LogisticRegression()\n",
    "\n",
    "def compute_LR_accuracy(model, X_train, Y_train):\n",
    "    '''\n",
    "    Split the training data into 5 subsets.\n",
    "    For each subset, \n",
    "        fit a model holding out that subset\n",
    "        compute the accuracy on that subset (the validation set)\n",
    "    Return the average MSE of these 5 folds.\n",
    "\n",
    "    Args:\n",
    "        model: an sklearn model with fit and predict functions \n",
    "        X_train (data_frame): Training data\n",
    "        Y_train (data_frame): Label \n",
    "\n",
    "    Return:\n",
    "        the average validation accuracy for the 5 splits.\n",
    "    '''\n",
    "    kf = KFold(n_splits=5)\n",
    "    validation_accuracy_LR = []\n",
    "    \n",
    "    for train_idx, valid_idx in kf.split(X_train):\n",
    "        # split the data\n",
    "        split_X_train, split_X_valid = X_train[train_idx] , X_train[valid_idx]\n",
    "        split_Y_train, split_Y_valid = Y_train[train_idx] , Y_train[valid_idx]\n",
    "        # Fit the model on the training split\n",
    "        Logistic_Regression.fit(split_X_train, split_Y_train)\n",
    "        \n",
    "        # Compute the RMSE on the validation split\n",
    "        accuracy = accuracy_score(split_Y_valid, Logistic_Regression.predict(split_X_valid))\n",
    "\n",
    "\n",
    "        validation_accuracy_LR.append(accuracy)\n",
    "        \n",
    "    return np.mean(validation_accuracy_LR)\n",
    "    \n",
    "\n",
    "#Use compute_LR_accuracy to determine how many of the first ùëÅ features we should use to get the highest\n",
    "\n",
    "range_of_num_features = range(1,X_train.shape[1]+1)\n",
    "\n",
    "accuracy_LR=[]\n",
    "\n",
    "for N in range_of_num_features:\n",
    "    print(f\"Trying first {N} features\")\n",
    "    model_LR = Logistic_Regression\n",
    "    \n",
    "    # compute the cross validation accuracy\n",
    "    accuracy = compute_LR_accuracy(model_LR, X_train[:,:N],y_train)\n",
    "    \n",
    "    print(\"\\tAccuracy:\", accuracy)\n",
    "    accuracy_LR.append(accuracy)\n",
    "\n",
    "\n",
    "best_num_features_LR = np.argmax(accuracy_LR) + 1\n",
    "best_accuracy_LR = accuracy_LR[best_num_features_LR-1]\n",
    "\n",
    "# Fit Logistic Regression Model\n",
    "Logistic_Regression.fit(X_train[:, :best_num_features_LR], y_train)\n",
    "\n",
    "# Predict points from the test set and calculate the accuracy\n",
    "test_accuracy_LR = accuracy_score(y_test, Logistic_Regression.predict(X_test[:, :best_num_features_LR]))\n",
    "\n",
    "# Minimum increase in accuracy\n",
    "diff, index = findMinDiff(accuracy_LR)\n",
    "\n",
    "print(\"Logistic Regression best number of features\", best_num_features_LR)\n",
    "print(\"KFold Validation Accuracy\", best_accuracy_LR)\n",
    "print(\"Logistic Regression Test Accuracy\", test_accuracy_LR)\n",
    "print(\"Minimum increase in accuracy is from features: \", index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFVFEcHbYZ2s"
   },
   "source": [
    "Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEnYHj6QYZ2v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29773463, 0.29934211, 0.32441472, 0.27702703, 0.32764505])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "scores_clf = cross_val_score(clf, X, y, cv=5)\n",
    "scores_clf\n",
    "#clf = clf.fit(X_train, y_train)\n",
    "#y_pred_clf=clf.predict(X_test)\n",
    "#accuracy_score(y_test,y_pred_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tpszr_PYZ2y"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FQol7rtYZ20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31391586, 0.3125    , 0.35451505, 0.31418919, 0.36518771])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(max_depth=50, random_state=0)\n",
    "scores_RF = cross_val_score(RF, X, y, cv=5)\n",
    "scores_RF\n",
    "#RF.fit(X_train, y_train)\n",
    "#y_pred_RF=RF.predict(X_test)\n",
    "#accuracy_score(y_test,y_pred_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SyE7AUwRYZ25"
   },
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ihUYRjyHYZ28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41423948, 0.38157895, 0.41471572, 0.40878378, 0.37542662])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC(kernel='linear',probability=True,random_state=42)\n",
    "scores_svm = cross_val_score(svm, X, y, cv=5)\n",
    "scores_svm\n",
    "#svm.fit(X_train,y_train)\n",
    "#y_pred_svm= svm.predict(X_test)\n",
    "#accuracy_score(y_test,y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.39805825, 0.38815789, 0.37458194, 0.43243243, 0.36177474]),\n",
       " array([0.2815534 , 0.28618421, 0.31438127, 0.2972973 , 0.31399317]),\n",
       " array([0.28478964, 0.31907895, 0.32107023, 0.28378378, 0.31740614]),\n",
       " array([0.31391586, 0.3125    , 0.35451505, 0.31418919, 0.36518771]),\n",
       " array([0.41423948, 0.38157895, 0.41471572, 0.40878378, 0.37542662]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 Fold Cross Validation\n",
    "\n",
    "scores_LR = cross_val_score(Logistic_Regression, X, y, cv=5)\n",
    "scores_KNN = cross_val_score(neigh, X, y, cv=5)\n",
    "scores_clf = cross_val_score(clf, X, y, cv=5)\n",
    "scores_RF = cross_val_score(RF, X, y, cv=5)\n",
    "scores_svm = cross_val_score(svm, X, y, cv=5)\n",
    "\n",
    "scores_LR,scores_KNN,scores_clf,scores_RF,scores_svm"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GradProject_NB3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
